{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5245866-4baf-47f4-8a6c-33865fc619a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 164 tensors from /home/technoidentity/Downloads/gemma-2b.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma\n",
      "llama_model_loader: - kv   1:                               general.name str              = gemma-2b\n",
      "llama_model_loader: - kv   2:                       gemma.context_length u32              = 8192\n",
      "llama_model_loader: - kv   3:                          gemma.block_count u32              = 18\n",
      "llama_model_loader: - kv   4:                     gemma.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv   5:                  gemma.feed_forward_length u32              = 16384\n",
      "llama_model_loader: - kv   6:                 gemma.attention.head_count u32              = 8\n",
      "llama_model_loader: - kv   7:              gemma.attention.head_count_kv u32              = 1\n",
      "llama_model_loader: - kv   8:                 gemma.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv   9:               gemma.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  10:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  13:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  14:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  15:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,256128]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,256128]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,256128]  = [3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - type  f32:  164 tensors\n",
      "llm_load_vocab: special tokens cache size = 388\n",
      "llm_load_vocab: token to piece cache size = 1.6014 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = gemma\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 256128\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 2048\n",
      "llm_load_print_meta: n_layer          = 18\n",
      "llm_load_print_meta: n_head           = 8\n",
      "llm_load_print_meta: n_head_kv        = 1\n",
      "llm_load_print_meta: n_rot            = 256\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 256\n",
      "llm_load_print_meta: n_embd_head_v    = 256\n",
      "llm_load_print_meta: n_gqa            = 8\n",
      "llm_load_print_meta: n_embd_k_gqa     = 256\n",
      "llm_load_print_meta: n_embd_v_gqa     = 256\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 16384\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 2B\n",
      "llm_load_print_meta: model ftype      = all F32 (guessed)\n",
      "llm_load_print_meta: model params     = 2.51 B\n",
      "llm_load_print_meta: model size       = 9.34 GiB (32.00 BPW) \n",
      "llm_load_print_meta: general.name     = gemma-2b\n",
      "llm_load_print_meta: BOS token        = 2 '<bos>'\n",
      "llm_load_print_meta: EOS token        = 1 '<eos>'\n",
      "llm_load_print_meta: UNK token        = 3 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<pad>'\n",
      "llm_load_print_meta: LF token         = 227 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 107 '<end_of_turn>'\n",
      "llm_load_print_meta: max token length = 93\n",
      "llm_load_tensors: ggml ctx size =    0.08 MiB\n",
      "llm_load_tensors:        CPU buffer size =  9561.29 MiB\n",
      ".............................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =     9.00 MiB\n",
      "llama_new_context_with_model: KV self size  =    9.00 MiB, K (f16):    4.50 MiB, V (f16):    4.50 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.98 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    31.52 MiB\n",
      "llama_new_context_with_model: graph nodes  = 601\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '3', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '1', 'general.architecture': 'gemma', 'gemma.feed_forward_length': '16384', 'gemma.attention.head_count': '8', 'general.name': 'gemma-2b', 'gemma.context_length': '8192', 'gemma.block_count': '18', 'gemma.embedding_length': '2048', 'gemma.attention.head_count_kv': '1', 'gemma.attention.key_length': '256', 'tokenizer.ggml.model': 'llama', 'gemma.attention.value_length': '256', 'gemma.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.bos_token_id': '2'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "llm = LlamaCpp(model_path=\"/home/technoidentity/Downloads/gemma-2b.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc759bee-5cef-486e-8ee8-9b08ce50d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class MultiplicationToolSchema(BaseModel):\n",
    "    operation: str\n",
    "    number1: float\n",
    "    number2: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86a2e9b-c527-473d-bdcf-7710a9d5befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "def multiplication_tool_function(input: dict) -> float:\n",
    "    multiplication_tool_schema = MultiplicationToolSchema.parse_obj(input)\n",
    "    return multiplication_tool_schema.number1 * multiplication_tool_schema.number2\n",
    "\n",
    "multiplication_tool = Tool(\n",
    "    name=\"multiplication\",\n",
    "    description=\"Multiplies two numbers.\",\n",
    "    func=multiplication_tool_function,\n",
    "    input_schema=MultiplicationToolSchema.schema(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afb1e8c-146e-4eab-a6c3-3190d9cd0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_prompt = \"you are a powerful assistant, with knowledge on various things.But you don't have any knowledge on how to perform multiplication or find the product of any two numbers.You must always try to use one of the available tools to provide an answer for anything related to multiplication\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b009404a-7239-4717-bbe0-9d769dd962dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict,List\n",
    "from langchain.schema import BaseMessage\n",
    "\n",
    "class CustomMessageFormatter:\n",
    "    def format_to_messages(self, input_data: Dict[str, str]) -> List[BaseMessage]:\n",
    "        return [\n",
    "            HumanMessage(content=f\"{input_data['operation']} {input_data['number1']} {input_data['operation_symbol']} {input_data['number2']}\"),\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64094519-ad2a-4196-8b50-4152992f19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplication_prompt = \"{{ operation }} {{ number1 }} {{ operation_symbol }} {{ number2 }}}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74cacdcb-a2d7-4504-b8f0-b7228deec95d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'input_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_tool_calling_agent\n\u001b[0;32m----> 3\u001b[0m multiplication_agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tool_calling_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmultiplication_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiplication_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_formatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCustomMessageFormatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pythonPrac/env/lib/python3.12/site-packages/langchain/agents/tool_calling_agent/base.py:89\u001b[0m, in \u001b[0;36mcreate_tool_calling_agent\u001b[0;34m(llm, tools, prompt, message_formatter)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_tool_calling_agent\u001b[39m(\n\u001b[1;32m     19\u001b[0m     llm: BaseLanguageModel,\n\u001b[1;32m     20\u001b[0m     tools: Sequence[BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     message_formatter: MessageFormatter \u001b[38;5;241m=\u001b[39m format_to_tool_messages,\n\u001b[1;32m     24\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable:\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an agent that uses tools.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m            messages will be passed in here.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     missing_vars \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m}\u001b[38;5;241m.\u001b[39mdifference(\n\u001b[0;32m---> 89\u001b[0m         \u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_variables\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(prompt\u001b[38;5;241m.\u001b[39mpartial_variables)\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'input_variables'"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "multiplication_agent = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=[multiplication_tool],\n",
    "    prompt=multiplication_prompt,\n",
    "    message_formatter=CustomMessageFormatter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbc9ca-a849-4623-b460-c1f76c07b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "multiplication_agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=multiplication_agent,\n",
    "    tools=[multiplication_tool],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9f8a4-1bd4-4c58-9c87-f25877dab969",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = multiplication_agent_executor.run(\n",
    "    input={\n",
    "        \"operation\": \"multiply\",\n",
    "        \"number1\": 5,\n",
    "        \"number2\": 3,\n",
    "    }\n",
    ")\n",
    "print(product) # Output: 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2fb5914-3a81-4107-9e0b-7bdd7bf68a73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.schema.formatters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMessage, HumanMessage\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMessageFormatter\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomMessageFormatter\u001b[39;00m(BaseMessageFormatter):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_to_messages\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.schema.formatters'"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "from langchain.schema import BaseMessage, HumanMessage\n",
    "from langchain.schema import BaseMessageFormatter\n",
    "\n",
    "class CustomMessageFormatter(BaseMessageFormatter):\n",
    "    def format_to_messages(self, input_data: Dict[str, float]) -> List[BaseMessage]:\n",
    "        return [HumanMessage(content=f\"{input_data['number1']} * {input_data['number2']}\")]\n",
    "\n",
    "# Create a multiplication tool\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "class MultiplyTool(BaseTool):\n",
    "    name = \"multiply\"\n",
    "    description = \"Multiply two numbers\"\n",
    "    args_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"number1\": {\"type\": \"number\"},\n",
    "            \"number2\": {\"type\": \"number\"},\n",
    "        },\n",
    "        \"required\": [\"number1\", \"number2\"],\n",
    "    }\n",
    "\n",
    "    def _run(self, number1: float, number2: float) -> float:\n",
    "        return number1 * number2\n",
    "\n",
    "# Create a custom tool\n",
    "custom_tool = MultiplyTool(name=\"custom_multiply\")\n",
    "\n",
    "# Create a custom message formatter\n",
    "message_formatter = CustomMessageFormatter()\n",
    "\n",
    "# Create a tool input\n",
    "tool_input = {\"number1\": 3.14, \"number2\": 2.718}\n",
    "\n",
    "# Format the tool input\n",
    "formatted_input = message_formatter.format(tool_input)\n",
    "\n",
    "# Pass the formatted input to the custom tool\n",
    "output = custom_tool.run(formatted_input)\n",
    "\n",
    "# Print the output\n",
    "print(output)  # Output: 8.53472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96627cb-f923-4af7-90a9-50ffded29a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
