{
 "cells": [
  {
   "cell_type": "raw",
   "id": "07848ad3-e656-45bd-b676-052a2a397383",
   "metadata": {},
   "source": [
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3fb92e-7780-4dac-ab1c-6f558c5735ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a702ff0-f50b-493f-a46d-f07abe9f0a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's data-driven world because they enable efficient processing and analysis of large amounts of text data. Here are some key reasons why they are important:\n",
      "\n",
      "1. **Speed and Efficiency**: Fast language models can process text quickly, making them ideal for applications where speed is essential, such as real-time text analysis, sentiment analysis, and language translation.\n",
      "2. **Scalability**: They can handle large volumes of data, which is particularly useful in industries that generate vast amounts of text data, like social media, customer service, and data analytics.\n",
      "3. **Improved Accuracy**: By processing text quickly, fast language models can analyze and understand text more accurately, leading to better decision-making in applications like natural language processing (NLP) and machine learning.\n",
      "4. **Enhanced User Experience**: Fast language models can provide instant responses, making interactions with applications more seamless and user-friendly, especially in chatbots and virtual assistants.\n",
      "5. **Competitive Advantage**: Companies that adopt fast language models can gain a competitive edge by processing and analyzing data faster than their competitors, leading to faster time-to-market and better customer satisfaction.\n",
      "6. **Data Insights**: Fast language models can uncover hidden patterns and trends in text data, providing valuable insights that can inform business strategies and improve operational efficiency.\n",
      "7. **Automation**: They can automate many tasks that previously required human intervention, freeing up resources for more strategic activities.\n",
      "\n",
      "In summary, fast language models are important because they offer speed, scalability, accuracy, and enhanced user experience, ultimately driving business value and competitiveness.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-groq-8b-8192-tool-use-preview\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0a3f3c-25e4-4ab9-8134-1167fdcbfea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3120ebf5-a5e0-4c25-b0fd-e014b95a3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is 5.25 times 7.39?\n",
    "Thought: I need to multiply 5.25 by 7.39\n",
    "Action: calculate: 5.25 * 7.39\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 38.7975\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The product of 5.25 and 7.39 is 38.7975\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def calculate(operation : str) -> float:\n",
    "    return eval(operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dceed6e-669a-4b36-9770-903a05b10853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\"]\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f889c0f5-f4c2-4099-a287-975b3d08f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to multiply 1.234 by 7.924\n",
      "Action: calculate: 1.234 * 7.924\n",
      "PAUSE\n",
      "Observation: 9.778216\n",
      "Answer: The product of 1.234 and 7.924 is 9.778216\n"
     ]
    }
   ],
   "source": [
    "loop(3,\"What is product of 1.234 and 7.924?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0921a-ec71-443f-9deb-07ab9e2e8b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
