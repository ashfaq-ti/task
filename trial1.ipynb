{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177486d6-908d-4e68-8649-2e5cb7c4d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 164 tensors from /home/technoidentity/Downloads/gemma-2b.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma\n",
      "llama_model_loader: - kv   1:                               general.name str              = gemma-2b\n",
      "llama_model_loader: - kv   2:                       gemma.context_length u32              = 8192\n",
      "llama_model_loader: - kv   3:                          gemma.block_count u32              = 18\n",
      "llama_model_loader: - kv   4:                     gemma.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv   5:                  gemma.feed_forward_length u32              = 16384\n",
      "llama_model_loader: - kv   6:                 gemma.attention.head_count u32              = 8\n",
      "llama_model_loader: - kv   7:              gemma.attention.head_count_kv u32              = 1\n",
      "llama_model_loader: - kv   8:                 gemma.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv   9:               gemma.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  10:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  13:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  14:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  15:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,256128]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,256128]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,256128]  = [3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - type  f32:  164 tensors\n",
      "llm_load_vocab: special tokens cache size = 388\n",
      "llm_load_vocab: token to piece cache size = 1.6014 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = gemma\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 256128\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 2048\n",
      "llm_load_print_meta: n_layer          = 18\n",
      "llm_load_print_meta: n_head           = 8\n",
      "llm_load_print_meta: n_head_kv        = 1\n",
      "llm_load_print_meta: n_rot            = 256\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 256\n",
      "llm_load_print_meta: n_embd_head_v    = 256\n",
      "llm_load_print_meta: n_gqa            = 8\n",
      "llm_load_print_meta: n_embd_k_gqa     = 256\n",
      "llm_load_print_meta: n_embd_v_gqa     = 256\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 16384\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 2B\n",
      "llm_load_print_meta: model ftype      = all F32 (guessed)\n",
      "llm_load_print_meta: model params     = 2.51 B\n",
      "llm_load_print_meta: model size       = 9.34 GiB (32.00 BPW) \n",
      "llm_load_print_meta: general.name     = gemma-2b\n",
      "llm_load_print_meta: BOS token        = 2 '<bos>'\n",
      "llm_load_print_meta: EOS token        = 1 '<eos>'\n",
      "llm_load_print_meta: UNK token        = 3 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<pad>'\n",
      "llm_load_print_meta: LF token         = 227 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 107 '<end_of_turn>'\n",
      "llm_load_print_meta: max token length = 93\n",
      "llm_load_tensors: ggml ctx size =    0.08 MiB\n",
      "llm_load_tensors:        CPU buffer size =  9561.29 MiB\n",
      ".............................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =     9.00 MiB\n",
      "llama_new_context_with_model: KV self size  =    9.00 MiB, K (f16):    4.50 MiB, V (f16):    4.50 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.98 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    31.52 MiB\n",
      "llama_new_context_with_model: graph nodes  = 601\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '3', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '1', 'general.architecture': 'gemma', 'gemma.feed_forward_length': '16384', 'gemma.attention.head_count': '8', 'general.name': 'gemma-2b', 'gemma.context_length': '8192', 'gemma.block_count': '18', 'gemma.embedding_length': '2048', 'gemma.attention.head_count_kv': '1', 'gemma.attention.key_length': '256', 'tokenizer.ggml.model': 'llama', 'gemma.attention.value_length': '256', 'gemma.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.bos_token_id': '2'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "llm = LlamaCpp(model_path=\"/home/technoidentity/Downloads/gemma-2b.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f1eb56-b332-47ff-986e-06a4d253d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import BaseTool\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11b7967e-d516-4549-ae73-bda2efc308d3",
   "metadata": {},
   "source": [
    "class MultiplicationTool(BaseTool):\n",
    "    name = 'MultiplicationTool'\n",
    "    description = \"this tool can be used to get the product of two numbers\"\n",
    "\n",
    "    def _run(self,num1:int,num2:int) -> int:\n",
    "        return num1 * num2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ce9a362-3cb1-4393-80b1-beb9bf063d5b",
   "metadata": {},
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b486346-fe13-4e55-a8c2-a48b8fdc8003",
   "metadata": {},
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d08bfac4-d017-4248-8580-f127fec930e7",
   "metadata": {},
   "source": [
    "tools = [multiply]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd88c0df-b332-40af-810f-7a346e0ca52f",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but any math\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374e694f-57bd-426b-b470-78a96374b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5c77c8-db8f-466b-b1a6-5544ad998283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicationTool(input : str =\"\") -> str:\n",
    "    words = input.split()\n",
    "    \n",
    "    # Extract numbers\n",
    "    numbers = [float(word) for word in words if word.isdigit()]\n",
    "    prod = 1\n",
    "    for num in numbers:\n",
    "        prod *= num\n",
    "    return f\"the product is {prod}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27dd3ac6-d6d3-4aa0-9b0b-3f81732522d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = 'multiplicationTool',\n",
    "        func = multiplicationTool,\n",
    "        description = 'useful for performing multiplication or finding a product of two numbers,input should be 2 numbers only',\n",
    "        input_variables=[\"num1 : float\", \"num2 : float\"],\n",
    "        return_type=str,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "815fc7c1-191a-4e3c-ba0c-74328a4430ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7adf54-f756-42cc-9289-9d2b306e64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_prompt = \"you are a powerful assistant, with knowledge on various things.But you don't have any knowledge of math, so use tools to solve math problems first,don't generate any new input.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475d852d-9028-4fd4-8d7c-5779dac0b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/technoidentity/pythonPrac/env/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "mul_agent = initialize_agent(\n",
    "    agent = 'conversational-react-description',\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    verbose = False,\n",
    "    SystemMessagePromptTemplate = fixed_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce599468-7fc3-4dad-85ac-c9cfb26171a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " 'InputType',\n",
       " 'OutputType',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__ror__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '__weakref__',\n",
       " '_abatch_with_config',\n",
       " '_abc_impl',\n",
       " '_acall',\n",
       " '_acall_with_config',\n",
       " '_aiter_next_step',\n",
       " '_aperform_agent_action',\n",
       " '_areturn',\n",
       " '_atake_next_step',\n",
       " '_atransform_stream_with_config',\n",
       " '_batch_with_config',\n",
       " '_calculate_keys',\n",
       " '_call',\n",
       " '_call_with_config',\n",
       " '_chain_type',\n",
       " '_consume_next_step',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_tool_return',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " '_iter_next_step',\n",
       " '_perform_agent_action',\n",
       " '_prepare_intermediate_steps',\n",
       " '_return',\n",
       " '_run_output_key',\n",
       " '_should_continue',\n",
       " '_take_next_step',\n",
       " '_transform_stream_with_config',\n",
       " '_validate_inputs',\n",
       " '_validate_outputs',\n",
       " 'abatch',\n",
       " 'abatch_as_completed',\n",
       " 'acall',\n",
       " 'agent',\n",
       " 'ainvoke',\n",
       " 'apply',\n",
       " 'aprep_inputs',\n",
       " 'aprep_outputs',\n",
       " 'arun',\n",
       " 'as_tool',\n",
       " 'assign',\n",
       " 'astream',\n",
       " 'astream_events',\n",
       " 'astream_log',\n",
       " 'atransform',\n",
       " 'batch',\n",
       " 'batch_as_completed',\n",
       " 'bind',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'config_schema',\n",
       " 'config_specs',\n",
       " 'configurable_alternatives',\n",
       " 'configurable_fields',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'early_stopping_method',\n",
       " 'from_agent_and_tools',\n",
       " 'from_orm',\n",
       " 'get_graph',\n",
       " 'get_input_schema',\n",
       " 'get_lc_namespace',\n",
       " 'get_name',\n",
       " 'get_output_schema',\n",
       " 'get_prompts',\n",
       " 'handle_parsing_errors',\n",
       " 'input_keys',\n",
       " 'input_schema',\n",
       " 'invoke',\n",
       " 'is_lc_serializable',\n",
       " 'iter',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'lookup_tool',\n",
       " 'map',\n",
       " 'max_execution_time',\n",
       " 'max_iterations',\n",
       " 'memory',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'output_keys',\n",
       " 'output_schema',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'pick',\n",
       " 'pipe',\n",
       " 'prep_inputs',\n",
       " 'prep_outputs',\n",
       " 'raise_callback_manager_deprecation',\n",
       " 'return_intermediate_steps',\n",
       " 'run',\n",
       " 'save',\n",
       " 'save_agent',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'set_verbose',\n",
       " 'stream',\n",
       " 'tags',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'tools',\n",
       " 'transform',\n",
       " 'trim_intermediate_steps',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_runnable_agent',\n",
       " 'validate_tools',\n",
       " 'verbose',\n",
       " 'with_alisteners',\n",
       " 'with_config',\n",
       " 'with_fallbacks',\n",
       " 'with_listeners',\n",
       " 'with_retry',\n",
       " 'with_types']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mul_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30898ce-3f7b-4ace-88f0-59f075518f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/technoidentity/pythonPrac/env/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "mul_agent({'input' : 'what is the product of 5.25 and 2.2?', 'chat_history' : []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c2de0-4a49-43ee-873d-3740b8f51ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
